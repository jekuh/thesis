%=========================================
% 	Methodology		 
%=========================================
\chapter{Concept and Design}

Chapter four examines the tools,setups and various techniques used in tackling our article  classification problem.  we  take a look at weka, our data mining tool,  setting up weka, pre-processing our data in weka, and  making use of weka built in machine learning algorithms to build a model classifier.

\subsection{Weka}
Waikato Environment for Knowledge Analysis (WEKA), is  a java based open-source data mining tool, developed by the University of Waikato.(cit src). Weka is used in education, research, and industries, has also  been implemented in Big Data technologies such as Hadoop, weka is a platform independent software, running on windows, Linux, and Mac see figure 1 for big picture of weka
\subsection{Weka integration with Java (image)}

\subsection{ Data pre-processing in weka(sample article representation in arrf format)}
An Attribute Relation File Format (ARFF) , is the popularly used data format in weka, but weka can also read from Comma Separated Vaule(CSV) data format
pros and cons of ARRF file and reading from databases.
Taking a loot at sample arrf representaion of an article pre-processed data-set in figure x
article-train-arff vs article-test.arff.
We recall from chapter  2 that the classification process used training set to train the model to predict unseen data. so in our case , we are training , evaluating, and applying a classifier to classify newspaper articles into front and non front page articles( figure x )
\subsection{ classification in weka(image)}


